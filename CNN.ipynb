{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10557/10557 [00:29<00:00, 354.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10391"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "directory = 'data/train'\n",
    "\n",
    "length_list = []\n",
    "valence_values=[]\n",
    "\n",
    "recordings = []\n",
    "\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.pkl'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            if data['valence'] != 2.333 and len(data['audio_data']) < 91000:\n",
    "                length_list.append(len(data['audio_data']))\n",
    "                valence_values.append(data['valence'])\n",
    "                recordings.append(data['audio_data'])\n",
    "\n",
    "valence_values = np.array(valence_values)\n",
    "len(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest_quarter(number):\n",
    "    # Assuming 'number' could be a numpy array with a single value\n",
    "    if isinstance(number, np.ndarray) and number.size == 1:\n",
    "        number = number.item()  # Convert single-item array to scalar\n",
    "    \n",
    "    # Ensure the number is within the 1 to 5 range before processing\n",
    "    number = np.clip(number, 1, 5)\n",
    "    # Scale number to shift quarters to whole numbers, round, and rescale\n",
    "    rounded_number = np.round(number * 4) / 4\n",
    "    # Clip again to ensure no out-of-range values after rounding\n",
    "    rounded_number = np.clip(rounded_number, 1, 5)\n",
    "    return rounded_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "# Pad the recordings to have the same length\n",
    "max_length = max(len(array) for array in recordings)  # Find the maximum length\n",
    "\n",
    "# Pad each array to have the maximum length\n",
    "padded_arrays = np.array([np.pad(array, (0, max_length - len(array)), mode='constant') for array in recordings])\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "# Split the data and labels into training and testing sets\n",
    "X_train, X_test_help, y_train, y_test_help = train_test_split(padded_arrays, valence_values, test_size=0.4, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_help, y_test_help, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "# Create a DataLoader for the training set, test set, and validation set\n",
    "\n",
    "batch_size = 256  # You can adjust the batch size depending on your system's capability\n",
    "\n",
    "# Convert input data and labels to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Use float32 for input features\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Use float32 for labels\n",
    "\n",
    "# Create a dataset from tensors\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "############################################################################################################\n",
    "# Repeat the same process for the test set\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "# Repeat the same process for the validation set\n",
    "X_validation_tensor = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)\n",
    "y_validation_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "validation_dataset = TensorDataset(X_validation_tensor, y_validation_tensor)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6234, 1, 90948]), torch.Size([6234]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.tensors[0].shape, train_loader.dataset.tensors[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Set random seed for reproducibility\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # Convolutional Layer 1\n",
    "        self.layers.append(nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3, padding=1))\n",
    "        self.layers.append(nn.BatchNorm1d(4))\n",
    "        self.layers.append(nn.MaxPool1d(kernel_size=3))\n",
    "\n",
    "        self.layers.append(nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3, padding=1))\n",
    "        self.layers.append(nn.BatchNorm1d(2))\n",
    "        self.layers.append(nn.MaxPool1d(kernel_size=3))\n",
    "\n",
    "        self.layers.append(nn.Conv1d(in_channels=2, out_channels=1, kernel_size=3, padding=1))\n",
    "        self.layers.append(nn.BatchNorm1d(1))\n",
    "        self.layers.append(nn.MaxPool1d(kernel_size=3))\n",
    "\n",
    "        self.layers.append(nn.Flatten())\n",
    "        self.layers.append(nn.Linear(3368, 1024))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(1024, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            #print(x.shape)\n",
    "        return x.view(-1)\n",
    "\n",
    "\n",
    "### CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Training Cycle\n",
    "\n",
    "def train_model(MLP_model, optimizer, num_epochs):\n",
    "        criterion = nn.MSELoss()\n",
    "        # Training loop\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            total_loss = 0\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "                outputs = MLP_model(inputs)  # Forward pass\n",
    "                loss = criterion(outputs, labels)  # Compute the loss\n",
    "                loss.backward()  # Backward pass\n",
    "\n",
    "                # Update weights using the step function of our custom ADAM optimizer\n",
    "                optimizer.step()\n",
    "\n",
    "                # Store the loss. loss.item() gets the value in a tensor. This only works for scalars.\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}')\n",
    "        print(f'MSE on validation set: {evaluate_model(MLP_model, validation_loader):.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model(MLP_model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        ### Calculate MSE \n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = MLP_model(inputs)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(labels.cpu().numpy())\n",
    "        predictions = np.array(predictions)\n",
    "        actuals = np.array(actuals)\n",
    "        mse = np.mean((predictions - actuals) ** 2)\n",
    "        print(f'Mean Squared Error: {mse:.4f}')\n",
    "        for i in range(10):\n",
    "            print(f\"Predictions: {predictions[i]}\")\n",
    "            print(f\"Actuals: {actuals[i]}\")\n",
    "\n",
    "        ### Calculate confusion matrix\n",
    "        rounded_predictions = round_to_nearest_quarter(predictions)\n",
    "        cm = confusion_matrix(actuals, rounded_predictions)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=np.arange(1, 6), yticklabels=np.arange(1, 6))\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:32<10:14, 32.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 10.5304\n"
     ]
    }
   ],
   "source": [
    "modelCNN = CNN().to(device)\n",
    "optimizer = optim.Adagrad(modelCNN.parameters(), lr=0.001)\n",
    "train_model(modelCNN, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.3032\n",
      "Predictions: 2.560722827911377\n",
      "Actuals: 1.75\n",
      "Predictions: 3.3508501052856445\n",
      "Actuals: 3.75\n",
      "Predictions: 2.276808977127075\n",
      "Actuals: 4.25\n",
      "Predictions: 2.5158779621124268\n",
      "Actuals: 3.75\n",
      "Predictions: 2.4128005504608154\n",
      "Actuals: 2.75\n",
      "Predictions: 2.1952083110809326\n",
      "Actuals: 2.5\n",
      "Predictions: 1.8099901676177979\n",
      "Actuals: 2.5\n",
      "Predictions: 2.427412271499634\n",
      "Actuals: 2.25\n",
      "Predictions: 2.223294496536255\n",
      "Actuals: 2.5\n",
      "Predictions: 2.7647290229797363\n",
      "Actuals: 4.0\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(modelCNN, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
